{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17ba4ea9-8470-4877-a5d5-730b1d70bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost 10-Fold 학습을 시작합니다...\n",
      "0:\tlearn: 1.0926989\ttest: 1.0930168\tbest: 1.0930168 (0)\ttotal: 23.1ms\tremaining: 1m 9s\n",
      "500:\tlearn: 0.7823925\ttest: 0.8322591\tbest: 0.8321889 (372)\ttotal: 6.78s\tremaining: 33.8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8321888639\n",
      "bestIteration = 372\n",
      "\n",
      "Shrink model to first 373 iterations.\n",
      "Fold 1 완료\n",
      "0:\tlearn: 1.0928205\ttest: 1.0927078\tbest: 1.0927078 (0)\ttotal: 22.8ms\tremaining: 1m 8s\n",
      "500:\tlearn: 0.7869116\ttest: 0.7957377\tbest: 0.7956993 (493)\ttotal: 6.69s\tremaining: 33.4s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7953621402\n",
      "bestIteration = 597\n",
      "\n",
      "Shrink model to first 598 iterations.\n",
      "Fold 2 완료\n",
      "0:\tlearn: 1.0927811\ttest: 1.0928872\tbest: 1.0928872 (0)\ttotal: 14.5ms\tremaining: 43.4s\n",
      "500:\tlearn: 0.7848243\ttest: 0.8206176\tbest: 0.8196094 (324)\ttotal: 8.13s\tremaining: 40.6s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8196093565\n",
      "bestIteration = 324\n",
      "\n",
      "Shrink model to first 325 iterations.\n",
      "Fold 3 완료\n",
      "0:\tlearn: 1.0928511\ttest: 1.0927501\tbest: 1.0927501 (0)\ttotal: 22.2ms\tremaining: 1m 6s\n",
      "500:\tlearn: 0.7852775\ttest: 0.8042200\tbest: 0.8041333 (488)\ttotal: 6.25s\tremaining: 31.2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8037374655\n",
      "bestIteration = 611\n",
      "\n",
      "Shrink model to first 612 iterations.\n",
      "Fold 4 완료\n",
      "0:\tlearn: 1.0927645\ttest: 1.0928998\tbest: 1.0928998 (0)\ttotal: 19.5ms\tremaining: 58.5s\n",
      "500:\tlearn: 0.7844767\ttest: 0.8201974\tbest: 0.8201342 (400)\ttotal: 7.76s\tremaining: 38.7s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8200630867\n",
      "bestIteration = 551\n",
      "\n",
      "Shrink model to first 552 iterations.\n",
      "Fold 5 완료\n",
      "0:\tlearn: 1.0927524\ttest: 1.0929573\tbest: 1.0929573 (0)\ttotal: 11.1ms\tremaining: 33.4s\n",
      "500:\tlearn: 0.7837243\ttest: 0.8204288\tbest: 0.8204288 (500)\ttotal: 7.18s\tremaining: 35.8s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8203609078\n",
      "bestIteration = 523\n",
      "\n",
      "Shrink model to first 524 iterations.\n",
      "Fold 6 완료\n",
      "0:\tlearn: 1.0928561\ttest: 1.0928602\tbest: 1.0928602 (0)\ttotal: 19.2ms\tremaining: 57.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# 기본값에 가까운 안정적인 파라미터\u001b[39;00m\n\u001b[32m    105\u001b[39m model = CatBoostClassifier(\n\u001b[32m    106\u001b[39m     iterations=\u001b[32m3000\u001b[39m, \u001b[38;5;66;03m# 넉넉하게 설정 후 early_stopping으로 조절\u001b[39;00m\n\u001b[32m    107\u001b[39m     learning_rate=\u001b[32m0.01\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     verbose=\u001b[32m500\u001b[39m \u001b[38;5;66;03m# 500회마다 로그 출력\u001b[39;00m\n\u001b[32m    112\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m cat_oof[val_idx] = model.predict_proba(X_val)\n\u001b[32m    117\u001b[39m cat_test += model.predict_proba(X_test) / n_splits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\catboost\\core.py:5547\u001b[39m, in \u001b[36mCatBoostClassifier.fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   5544\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   5545\u001b[39m     CatBoostClassifier._check_is_compatible_loss(params[\u001b[33m'\u001b[39m\u001b[33mloss_function\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m5547\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5548\u001b[39m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5549\u001b[39m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5550\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\catboost\\core.py:2716\u001b[39m, in \u001b[36mCatBoost._fit\u001b[39m\u001b[34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[39m\n\u001b[32m   2713\u001b[39m allow_clear_pool = train_params[\u001b[33m\"\u001b[39m\u001b[33mallow_clear_pool\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2715\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[33m'\u001b[39m\u001b[33mTraining plots\u001b[39m\u001b[33m'\u001b[39m, [_get_train_dir(params)]):\n\u001b[32m-> \u001b[39m\u001b[32m2716\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2717\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meval_sets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minit_model\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[32m   2725\u001b[39m loss = \u001b[38;5;28mself\u001b[39m._object._get_loss_function_name()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\catboost\\core.py:1824\u001b[39m, in \u001b[36m_CatBoostBase._train\u001b[39m\u001b[34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[39m\n\u001b[32m   1823\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[32m-> \u001b[39m\u001b[32m1824\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1825\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_trained_model_attributes()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5430\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_catboost.pyx:5479\u001b[39m, in \u001b[36m_catboost._CatBoost._train\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 데이터 로드\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# --- [전처리 및 피처 엔지니어링] ---\n",
    "\n",
    "# 1. 결측치 및 이상치 처리\n",
    "train.fillna('NaN', inplace=True)\n",
    "test.fillna('NaN', inplace=True)\n",
    "train = train[(train['family_size'] <= 7)].reset_index(drop=True)\n",
    "\n",
    "# 2. 의미없는 변수 제거\n",
    "train.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
    "test.drop(['index', 'FLAG_MOBIL'], axis=1, inplace=True)\n",
    "\n",
    "# 3. DAYS_EMPLOYED 처리 (무직자 0 처리 및 양수 변환)\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "test['DAYS_EMPLOYED'] = test['DAYS_EMPLOYED'].map(lambda x: 0 if x > 0 else x)\n",
    "\n",
    "feats = ['DAYS_BIRTH', 'begin_month', 'DAYS_EMPLOYED']\n",
    "for feat in feats:\n",
    "    train[feat] = np.abs(train[feat])\n",
    "    test[feat] = np.abs(test[feat])\n",
    "\n",
    "# 4. 파생변수 생성 (실력자 버전)\n",
    "for df in [train, test]:\n",
    "    df['before_EMPLOYED'] = df['DAYS_BIRTH'] - df['DAYS_EMPLOYED']\n",
    "    df['income_total_befofeEMP_ratio'] = df['income_total'] / df['before_EMPLOYED']\n",
    "    df['Age'] = df['DAYS_BIRTH'] // 365\n",
    "    df['DAYS_BIRTH_m'] = np.floor(df['DAYS_BIRTH'] / 30) % 12\n",
    "    df['DAYS_BIRTH_w'] = np.floor(df['DAYS_BIRTH'] / 7) % 4\n",
    "    df['EMPLOYED'] = df['DAYS_EMPLOYED'] // 365\n",
    "    df['DAYS_EMPLOYED_m'] = np.floor(df['DAYS_EMPLOYED'] / 30) % 12\n",
    "    df['DAYS_EMPLOYED_w'] = np.floor(df['DAYS_EMPLOYED'] / 7) % 4\n",
    "    df['ability'] = df['income_total'] / (df['DAYS_BIRTH'] + df['DAYS_EMPLOYED'])\n",
    "    df['income_mean'] = df['income_total'] / df['family_size']\n",
    "    \n",
    "    # [핵심] ID 생성\n",
    "    df['ID'] = df['gender'].astype(str) + '_' + df['income_total'].astype(str) + '_' + \\\n",
    "               df['DAYS_BIRTH'].astype(str) + '_' + df['DAYS_EMPLOYED'].astype(str) + '_' + \\\n",
    "               df['work_phone'].astype(str) + '_' + df['phone'].astype(str) + '_' + \\\n",
    "               df['email'].astype(str) + '_' + df['family_size'].astype(str) + '_' + \\\n",
    "               df['income_type'].astype(str) + '_' + df['edu_type'].astype(str) + '_' + \\\n",
    "               df['family_type'].astype(str) + '_' + df['house_type'].astype(str) + '_' + \\\n",
    "               df['occyp_type'].astype(str)\n",
    "\n",
    "# 5. 다중공선성 제거 및 인코딩\n",
    "train.drop(['child_num'], axis=1, inplace=True) # child_num은 family_size와 상관관계 높음\n",
    "test.drop(['child_num'], axis=1, inplace=True)\n",
    "\n",
    "categorical_feats = ['gender', 'car', 'reality', 'income_type', 'edu_type', 'family_type', 'house_type', 'occyp_type', 'ID']\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "train[categorical_feats] = encoder.fit_transform(train[categorical_feats])\n",
    "test[categorical_feats] = encoder.transform(test[categorical_feats])\n",
    "train['ID'] = train['ID'].astype('int64')\n",
    "test['ID'] = test['ID'].astype('int64')\n",
    "\n",
    "# 6. 로그 스케일 및 클러스터링\n",
    "train['income_total'] = np.log1p(1 + train['income_total'])\n",
    "test['income_total'] = np.log1p(1 + test['income_total'])\n",
    "\n",
    "kmeans_train = train.drop(['credit'], axis=1)\n",
    "kmeans = KMeans(n_clusters=36, random_state=42).fit(kmeans_train)\n",
    "train['cluster'] = kmeans.predict(kmeans_train)\n",
    "test['cluster'] = kmeans.predict(test)\n",
    "\n",
    "# 7. 표준화\n",
    "numerical_feats = [f for f in train.columns if f not in categorical_feats + ['credit', 'income_total', 'cluster']]\n",
    "scaler = StandardScaler()\n",
    "train[numerical_feats] = scaler.fit_transform(train[numerical_feats])\n",
    "test[numerical_feats] = scaler.transform(test[numerical_feats])\n",
    "\n",
    "# --- [CatBoost 모델 학습] ---\n",
    "\n",
    "X = train.drop(['credit'], axis=1)\n",
    "y = train['credit']\n",
    "groups = train['ID'] # 동일 인물 그룹화\n",
    "X_test = test.copy()\n",
    "\n",
    "n_splits = 10\n",
    "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "cat_oof = np.zeros((train.shape[0], 3))\n",
    "cat_test = np.zeros((test.shape[0], 3))\n",
    "\n",
    "print(f\"CatBoost 10-Fold 학습을 시작합니다...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, groups=groups)):\n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # 기본값에 가까운 안정적인 파라미터\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=3000, # 넉넉하게 설정 후 early_stopping으로 조절\n",
    "        learning_rate=0.01,\n",
    "        loss_function='MultiClass',\n",
    "        random_seed=42,\n",
    "        early_stopping_rounds=200,\n",
    "        verbose=500 # 500회마다 로그 출력\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val), use_best_model=True)\n",
    "    \n",
    "    cat_oof[val_idx] = model.predict_proba(X_val)\n",
    "    cat_test += model.predict_proba(X_test) / n_splits\n",
    "    print(f\"Fold {fold+1} 완료\")\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"\\n[CatBoost 10-Fold CV Score]: {log_loss(y, cat_oof):.4f}\")\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission.iloc[:, 1:] = cat_test\n",
    "submission.to_csv('catboost_10fold_final.csv', index=False)\n",
    "print(\"제출 파일이 생성되었습니다: catboost_10fold_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d10aca-7685-4fed-b1a7-5044e08c6810",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
